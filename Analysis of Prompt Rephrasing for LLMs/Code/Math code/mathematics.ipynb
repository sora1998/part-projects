{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b84e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88239be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5299b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/yongc/Desktop/math_zero_shot_CoT2.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"correct\"] = correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"problem\", \"level\", \"type\", \"solution\", \"zero-shot CoT reasoning chain\", \"zero-shot CoT reasoning answer\", \"correct\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"correct\"] == 1].groupby(\"type\").count()[\"correct\"] / data.groupby(\"type\").count()[\"correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bcd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_arr = [\"Algebra\", \"Number Theory\", \"Probability\", \"Precalculus\", \"Geometry\"]\n",
    "acc = [25.42, 15.79, 11.11, 10.53, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d501fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.bar(type_arr, np.array(acc)/100, color = \"orange\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Distribution for Different Math Sub-categories\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_arr = [\"level 1\", \"level 2\", \"level 3\", \"level 4\", \"level 5\"]\n",
    "acc = [41.70, 21.70, 18.60, 5, 5]\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.bar(type_arr, np.array(acc)/100, color = \"orange\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Distribution for Different Levels of Difficulty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fddb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"type\"] == \"Number Theory\"][\"solution\"].iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_folder_path = \"C:/Users/yongc/Desktop/drugChat_promptEng/dataset/drugDataset\"\n",
    "drug_info_dict = {}\n",
    "for filename in tqdm(os.listdir(drug_folder_path)):\n",
    "    file_path = os.path.join(drug_folder_path, filename)\n",
    "    with open(file_path, \"r\", encoding = 'utf-8') as f:\n",
    "        curr_data = f.read()\n",
    "    smile_repr_str = get_smile_repr(curr_data)\n",
    "    drug_info_dict[smile_repr_str] = parse_sections(curr_data, root = smile_repr_str, layer = 2)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b041142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "problems = []\n",
    "answers = []\n",
    "folder_path = \"C:/Users/yongc/Desktop/mathematics_dataset-v1.0/train-medium\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
    "        for i in range(4):\n",
    "            if i % 2 == 0:\n",
    "                problems.append(f.readline().strip())\n",
    "            else:\n",
    "                answers.append(f.readline().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ecfb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"problems\"] = problems\n",
    "df[\"answers\"] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(108, len(problems))):\n",
    "    try:\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": problems[i] + \" Output the answer directly. Do not contain any words other than the answer.\"}],\n",
    "          temperature=0,\n",
    "          max_tokens=256,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        gpt_answers.append((i, resp))\n",
    "    except KeyboardInterrupt:\n",
    "        raise KeyboardInterrupt\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(10)\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": problems[i]} + \" Output the answer directly. Do not contain any words other than the answer.\"],\n",
    "          temperature=0,\n",
    "          max_tokens=256,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        gpt_answers.append((i, resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cae971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"zero-shot answer\"] = [e[1] for e in gpt_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "print(df.iloc[i * 10: i * 10 + 10][[\"answers\", \"zero-shot answer\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba025ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_correct = [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"zero_answer_correct\"] = zero_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b297035",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(zero_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_answers_CoT = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(problems))):\n",
    "    curr_problem = problems[i] + \"\\nLet's think step by step.\"\n",
    "    try:\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=1024,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        extract_problem = curr_problem + \"\\n\" + resp + \"\\n\" + \"Given the problem and the reasoning above, output the final answer directly. Do not contain any words other than the final answer.\"\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": extract_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=256,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        gpt_answers_CoT.append((i, resp))\n",
    "    except KeyboardInterrupt:\n",
    "        raise KeyboardInterrupt\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(10)\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=2048,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        extract_problem = curr_problem + \"\\n\" + resp + \"\\n\" + \"Given the problem and the reasoning above, output the final answer directly. Do not contain any words other than the final answer.\"\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": extract_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=256,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        gpt_answers_CoT.append((i, resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CoT answer\"] = [e[1] for e in gpt_answers_CoT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "print(df.iloc[i * 10: i * 10 + 10][[\"answers\", \"CoT answer\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9004fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_CoT = [1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correct_CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_answer_explained = []\n",
    "Explanation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9cb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "for i in tqdm(range(len(problems))):\n",
    "    curr_problem = problems[i] + \"\\nExplain the meaning of the problem in details and provide your answer.\"\n",
    "    try:\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=1024,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        extract_problem = curr_problem + \"\\n\" + resp + \"\\n\" + \"Given the problem and the explanation above, output the final answer directly. Do not contain any words other than the final answer.\"\n",
    "        Explanation.append((i, resp))\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": extract_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=256,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        gpt_answer_explained.append((i, resp))\n",
    "    except KeyboardInterrupt:\n",
    "        raise KeyboardInterrupt\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(10)\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=1024,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        extract_problem = curr_problem + \"\\n\" + resp + \"\\n\" + \"Given the problem and the explanation above, output the final answer directly. Do not contain any words other than the final answer.\"\n",
    "        Explanation.append((i, resp))\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": extract_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=256,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        gpt_answer_explained.append((i, resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734fa0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"explained\"] = [e[1] for e in gpt_answer_explained]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732da0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "print(df.iloc[i * 10: i * 10 + 10][[\"answers\", \"explained\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_explained = [1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ae155",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correct_explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAL_answer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45223d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "for i in tqdm(range(len(problems))):\n",
    "    curr_problem = problems[i] + \"\\nWrite a runnable python function that returns the answer. Do not include any text other than python code.\"\n",
    "    try:\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=1024,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        try:\n",
    "            output_stream = io.StringIO()\n",
    "            sys.stdout = output_stream\n",
    "            exec(resp)\n",
    "            printed_output = output_stream.getvalue()\n",
    "            sys.stdout = sys.__stdout__\n",
    "            value = int(printed_output.strip())\n",
    "            PAL_answer.append((i, value))\n",
    "        except:\n",
    "            PAL_answer.append(gpt_answers_CoT[i])\n",
    "    except KeyboardInterrupt:\n",
    "        raise KeyboardInterrupt\n",
    "    except Exception as e:\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=1024,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        try:\n",
    "            output_stream = io.StringIO()\n",
    "            sys.stdout = output_stream\n",
    "            exec(resp)\n",
    "            printed_output = output_stream.getvalue()\n",
    "            \n",
    "            sys.stdout = sys.__stdout__\n",
    "            value = int(printed_output.strip())\n",
    "            PAL_answer.append((i, value))\n",
    "        except:\n",
    "            PAL_answer.append(gpt_answers_CoT[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8da66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PAL\"] = [e[1] for e in PAL_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "print(df.iloc[i * 10: i * 10 + 10][[\"answers\", \"PAL\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_PAL = [1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e724fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correct_PAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "for i in tqdm(range(len(problems))):\n",
    "    curr_problem = problems[i] + \"\\nWrite a runnable python function that returns the answer. Do not include any text other than python code.\"\n",
    "    try:\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=1024,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        try:\n",
    "            output_stream = io.StringIO()\n",
    "            sys.stdout = output_stream\n",
    "            exec(resp)\n",
    "            printed_output = output_stream.getvalue()\n",
    "            sys.stdout = sys.__stdout__\n",
    "            value = int(printed_output.strip())\n",
    "            PAL_answer.append((i, value))\n",
    "        except:\n",
    "            PAL_answer.append(gpt_answers_CoT[i])\n",
    "    except KeyboardInterrupt:\n",
    "        raise KeyboardInterrupt\n",
    "    except Exception as e:\n",
    "        responses = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = [{\"role\": \"user\", \"content\": curr_problem}],\n",
    "          temperature=0,\n",
    "          max_tokens=1024,\n",
    "        )\n",
    "        resp = responses.choices[0].message.content\n",
    "        try:\n",
    "            output_stream = io.StringIO()\n",
    "            sys.stdout = output_stream\n",
    "            exec(resp)\n",
    "            printed_output = output_stream.getvalue()\n",
    "            \n",
    "            sys.stdout = sys.__stdout__\n",
    "            value = int(printed_output.strip())\n",
    "            PAL_answer.append((i, value))\n",
    "        except:\n",
    "            PAL_answer.append(gpt_answers_CoT[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
